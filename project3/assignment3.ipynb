{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d18ed92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d59a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_insulin_data():\n",
    "    insulin_df = pd.read_csv(\"InsulinData.csv\", parse_dates=[['Date', 'Time']], \\\n",
    "                             keep_date_col=True, low_memory=False)\n",
    "    insulin_df = insulin_df[['Date_Time', 'BWZ Carb Input (grams)']]\n",
    "    insulin_df = insulin_df.rename(columns={'BWZ Carb Input (grams)': 'Carb_Input'})\n",
    "    print('extracting insulin df: ' + str(insulin_df.shape))\n",
    "    return insulin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c858e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cgm_data(): \n",
    "    cgm_df = pd.read_csv('CGMData.csv', parse_dates=[['Date', 'Time']], keep_date_col=True, low_memory=False)\n",
    "    cgm_df = cgm_df[['Date_Time', 'Index','Sensor Glucose (mg/dL)', 'Date', 'Time']]\n",
    "    cgm_df = cgm_df.rename(columns={'Sensor Glucose (mg/dL)': 'Sensor_Glucose'})\n",
    "    print('extracting cgm df: ' + str(cgm_df.size))\n",
    "    return cgm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f506e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting insulin df: (41435, 2)\n",
      "extracting cgm df: 276715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82870"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "276715"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "insulin_df, cgm_df = load_insulin_data(), load_cgm_data()\n",
    "display(insulin_df.size)\n",
    "display(cgm_df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50762fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1ac041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = dt.datetime(2100, 12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e90202fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_meal_start_times(insulin_df, cgm_df):\n",
    "    \n",
    "    insulin_df = insulin_df[(insulin_df['Carb_Input'].notna()) & (insulin_df['Carb_Input'] != 0)]\n",
    "    insulin_df = insulin_df.set_index('Date_Time').sort_index().reset_index()\n",
    "    \n",
    "    # include only those meal periods for which the next carb intake is atleast after 2 hrs\n",
    "    mask = (insulin_df['Date_Time'].shift(-1, fill_value=inf) - insulin_df['Date_Time'] \\\n",
    "            >= dt.timedelta(hours=2))\n",
    "    \n",
    "    insulin_df = insulin_df[mask]\n",
    "    \n",
    "    # column rename is required for the following merge\n",
    "    insulin_df = insulin_df.rename(columns = {'Date_Time': 'Pseudo_Start_Time'})\n",
    "    \n",
    "    cgm_df = cgm_df[cgm_df['Sensor_Glucose'].notna()]\n",
    "    cgm_df = cgm_df.set_index('Date_Time').sort_index().reset_index()\n",
    "    \n",
    "    meal_df = pd.merge_asof(insulin_df, cgm_df, left_on='Pseudo_Start_Time', \\\n",
    "                            right_on='Date_Time', direction='forward')[['Date_Time', 'Carb_Input']]\n",
    "    \n",
    "    min, max = meal_df['Carb_Input'].min(), meal_df['Carb_Input'].max()\n",
    "    \n",
    "    # binning BWZ Carb Input (grams) into bins of range 20\n",
    "    meal_df['Carb_Input'] = (meal_df['Carb_Input'] - min) // 20\n",
    "    \n",
    "    return meal_df\n",
    "    \n",
    "meal_df = extract_meal_start_times(insulin_df, cgm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d9ab1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meal_data_matrix(cgm_df, meal_df):\n",
    "    \n",
    "    meal_data_list = []\n",
    "    ground_truth = []\n",
    "    \n",
    "    for _, row in meal_df.iterrows():\n",
    "        \n",
    "        meal_start = row['Date_Time'] - pd.DateOffset(minutes=30)\n",
    "        meal_end = row['Date_Time'] + pd.DateOffset(hours=2)\n",
    "        meal = cgm_df.loc[(cgm_df['Date_Time'] >= meal_start) & (cgm_df['Date_Time'] < meal_end)]\n",
    "        \n",
    "        # remove meal periods with <30 readings\n",
    "        if (meal_df.shape[0] < 30):\n",
    "            continue\n",
    "            \n",
    "        meal = meal[meal['Sensor_Glucose'].notna()]\n",
    "        meal = meal.set_index('Date_Time').sort_index().reset_index()\n",
    "\n",
    "        # remove readings <300 seconds apart\n",
    "        mask = (meal['Date_Time'].shift(-1, fill_value=inf) - meal['Date_Time'] \\\n",
    "                >= dt.timedelta(seconds=300))\n",
    "        \n",
    "        meal = meal[mask]\n",
    "\n",
    "        # only include meal_period if it has exactly 30 readings\n",
    "        if (meal.shape[0] == 30):\n",
    "            meal_data_list.append(meal['Sensor_Glucose'])\n",
    "            ground_truth.append(row['Carb_Input'])\n",
    "        \n",
    "    feature_matrix = pd.concat(meal_data_list, axis=1).transpose()\n",
    "    feature_matrix['label'] = ground_truth \n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d984b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_data_matrix = compute_meal_data_matrix(cgm_df, meal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a5b7235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy, iqr\n",
    "from scipy.signal import periodogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48c9e57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meal_feature_matrix(meal_data_matrix):\n",
    "    \n",
    "    # exclude ground truth\n",
    "    _input = meal_data_matrix.iloc[:, :-1]\n",
    "    \n",
    "    features = pd.DataFrame()\n",
    "    \n",
    "    velocity = _input.diff(axis=1).dropna(axis=1, how='all')\n",
    "    features['velocity_min'] = velocity.min(axis=1)\n",
    "    features['velocity_max'] = velocity.max(axis=1)\n",
    "    features['velocity_mean'] = velocity.mean(axis=1)\n",
    "\n",
    "    acceleration = velocity.diff(axis=1).dropna(axis=1, how='all')\n",
    "    features['acceleration_min'] = acceleration.min(axis=1)\n",
    "    features['acceleration_max'] = acceleration.max(axis=1)\n",
    "    features['acceleration_mean'] = acceleration.mean(axis=1)\n",
    "\n",
    "    features['entropy'] = _input.apply(lambda row: entropy(row, base=2), axis=1)\n",
    "    features['iqr'] = _input.apply(lambda row: entropy(row, base=2), axis=1)\n",
    "    \n",
    "    fft_values = _input.apply(lambda row: np.fft.fft(row), axis=1)\n",
    "\n",
    "    # get the indices of the frequencies sorted by decreasing amplitude\n",
    "    fft_indices = fft_values.apply(lambda row: np.argsort(np.abs(row))[::-1])\n",
    "\n",
    "    # select the first 6 peaks of each row\n",
    "    fft_peaks = fft_indices.apply(lambda row: row[:6])\n",
    "    fft_peaks = fft_peaks.apply(pd.Series)\n",
    "    fft_peaks.columns = ['fft_max_' + str(i+1) for i in fft_peaks.apply(pd.Series).columns]\n",
    "    \n",
    "    features = pd.concat([features, fft_peaks], axis=1)\n",
    "    \n",
    "    _input = meal_data_matrix.iloc[:, :-1]\n",
    "    psd = _input.apply(lambda row: periodogram(row)[1], axis=1)\n",
    "    psd = psd.apply(lambda row: [np.mean(row[0:5]), np.mean(row[5:10]), np.mean(row[10:16])])\n",
    "    psd = psd.apply(pd.Series)\n",
    "    psd.columns = ['psd1', 'psd2', 'psd3']\n",
    " \n",
    "    features = pd.concat([features, psd], axis=1)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f702d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "meal_feature_matrix = compute_meal_feature_matrix(meal_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eaf1c48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1390c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "meal_feature_matrix_scaled = pd.DataFrame(scaler.fit_transform(meal_feature_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a0c04",
   "metadata": {},
   "source": [
    "\n",
    "## KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1ff1e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6528fd1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=7, n_init=20, max_iter=100)\n",
    "\n",
    "# Fit the model to the data\n",
    "kmeans.fit(meal_feature_matrix_scaled)\n",
    "\n",
    "# Get the cluster labels for each data point\n",
    "labels = kmeans.labels_\n",
    "cluster_centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad66c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fc7d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = meal_data_matrix['label']\n",
    "cont_matrix = contingency_matrix(ground_truth, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f75b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(meal_data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd3aba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans SSE:  3268.9256795314514\n",
      "KMeans Purity:  0.3293269230769231\n",
      "KMeans Entropy:  2.169861476829342\n"
     ]
    }
   ],
   "source": [
    "# Calculate the SSE\n",
    "kmeans_sse = kmeans.inertia_\n",
    "\n",
    "# Calculate the purity\n",
    "kmeans_purity = np.sum(np.amax(cont_matrix, axis=0)) / num_samples\n",
    "\n",
    "# Calculate the entropy\n",
    "kmeans_entropy = -np.sum((np.sum(cont_matrix, axis=1) / num_samples) *\n",
    "                  np.log2(np.sum(cont_matrix, axis=1) / num_samples))\n",
    "\n",
    "print(\"KMeans SSE: \", kmeans_sse)\n",
    "print(\"KMeans Purity: \", kmeans_purity)\n",
    "print(\"KMeans Entropy: \", kmeans_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3050e353",
   "metadata": {},
   "source": [
    "\n",
    "## DBSCAN Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa925ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "314dcf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=1.4, min_samples=4).fit(meal_feature_matrix_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3486e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_labels = dbscan.labels_.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1ed6f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan_labels[dbscan_labels == -1] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3322a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_matrix = pd.crosstab(ground_truth, dbscan_labels, dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10244e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBSCAN SSE:  480.30144364558606\n",
      "DBSCAN Purity:  0.18269230769230768\n",
      "DBSCAN Entropy:  1.4994102180291398\n"
     ]
    }
   ],
   "source": [
    "# Calculate the SSE\n",
    "\n",
    "# Change np.nan back to -1\n",
    "dbscan_labels = np.nan_to_num(dbscan_labels, nan=-1)\n",
    "\n",
    "meal_feature_matrix_scaled['label'] = dbscan_labels\n",
    "\n",
    "# Calculate the SSE for each cluster\n",
    "dbscan_sse = meal_feature_matrix_scaled[meal_feature_matrix_scaled['label'] != -1].groupby(['label']).apply(lambda x: ((x.iloc[:,:-1] - x.iloc[:,:-1].mean()) ** 2).sum().sum()).sum()\n",
    "\n",
    "# Calculate the purity\n",
    "dbscan_purity = np.sum(np.amax(cont_matrix, axis=0)) / num_samples\n",
    "\n",
    "# Calculate the entropy\n",
    "dbscan_entropy = -np.sum((np.sum(cont_matrix, axis=1) / num_samples) *\n",
    "                  np.log2(np.sum(cont_matrix, axis=1) / num_samples))\n",
    "\n",
    "print(\"DBSCAN SSE: \", dbscan_sse)\n",
    "print(\"DBSCAN Purity: \", dbscan_purity)\n",
    "print(\"DBSCAN Entropy: \", dbscan_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3122cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clustering evaluation results in a CSV file\n",
    "results = np.array([[kmeans_sse, dbscan_sse, kmeans_entropy, dbscan_entropy, kmeans_purity, dbscan_purity]])\n",
    "np.savetxt(\"Results.csv\", results, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8216785e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.077691</td>\n",
       "      <td>-0.640440</td>\n",
       "      <td>-0.526555</td>\n",
       "      <td>0.416087</td>\n",
       "      <td>-0.086528</td>\n",
       "      <td>0.986868</td>\n",
       "      <td>0.922688</td>\n",
       "      <td>0.922688</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.363179</td>\n",
       "      <td>0.363179</td>\n",
       "      <td>1.031509</td>\n",
       "      <td>-1.031509</td>\n",
       "      <td>0.841321</td>\n",
       "      <td>-0.620350</td>\n",
       "      <td>-0.564972</td>\n",
       "      <td>-0.556686</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.170161</td>\n",
       "      <td>0.158943</td>\n",
       "      <td>0.215751</td>\n",
       "      <td>0.290839</td>\n",
       "      <td>0.816591</td>\n",
       "      <td>0.693417</td>\n",
       "      <td>-0.908490</td>\n",
       "      <td>-0.908490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.363179</td>\n",
       "      <td>0.363179</td>\n",
       "      <td>-1.004775</td>\n",
       "      <td>1.004775</td>\n",
       "      <td>-1.147256</td>\n",
       "      <td>-0.546461</td>\n",
       "      <td>-0.528244</td>\n",
       "      <td>-0.493556</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.202476</td>\n",
       "      <td>0.044746</td>\n",
       "      <td>-0.160941</td>\n",
       "      <td>0.416087</td>\n",
       "      <td>-0.215545</td>\n",
       "      <td>0.595601</td>\n",
       "      <td>0.474676</td>\n",
       "      <td>0.474676</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.363179</td>\n",
       "      <td>0.363179</td>\n",
       "      <td>-1.004775</td>\n",
       "      <td>1.004775</td>\n",
       "      <td>0.841321</td>\n",
       "      <td>-0.419778</td>\n",
       "      <td>-0.636143</td>\n",
       "      <td>-0.641431</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.701617</td>\n",
       "      <td>-0.412045</td>\n",
       "      <td>1.534175</td>\n",
       "      <td>0.040344</td>\n",
       "      <td>-0.602597</td>\n",
       "      <td>0.497784</td>\n",
       "      <td>-2.661953</td>\n",
       "      <td>-2.661953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.363179</td>\n",
       "      <td>0.363179</td>\n",
       "      <td>-1.004775</td>\n",
       "      <td>1.004775</td>\n",
       "      <td>0.841321</td>\n",
       "      <td>0.369869</td>\n",
       "      <td>1.460540</td>\n",
       "      <td>1.204818</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.202476</td>\n",
       "      <td>-1.668219</td>\n",
       "      <td>-1.545840</td>\n",
       "      <td>0.290839</td>\n",
       "      <td>-0.473579</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.179628</td>\n",
       "      <td>0.179628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.363179</td>\n",
       "      <td>0.363179</td>\n",
       "      <td>1.031509</td>\n",
       "      <td>-1.031509</td>\n",
       "      <td>-1.233716</td>\n",
       "      <td>-0.194140</td>\n",
       "      <td>0.457735</td>\n",
       "      <td>0.308719</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \n",
       "0  0.077691 -0.640440 -0.526555  0.416087 -0.086528  0.986868  0.922688  \\\n",
       "1 -1.170161  0.158943  0.215751  0.290839  0.816591  0.693417 -0.908490   \n",
       "2  0.202476  0.044746 -0.160941  0.416087 -0.215545  0.595601  0.474676   \n",
       "3  0.701617 -0.412045  1.534175  0.040344 -0.602597  0.497784 -2.661953   \n",
       "4  0.202476 -1.668219 -1.545840  0.290839 -0.473579  0.008700  0.179628   \n",
       "\n",
       "          7    8         9        10        11        12        13        14   \n",
       "0  0.922688  0.0 -0.363179  0.363179  1.031509 -1.031509  0.841321 -0.620350  \\\n",
       "1 -0.908490  0.0 -0.363179  0.363179 -1.004775  1.004775 -1.147256 -0.546461   \n",
       "2  0.474676  0.0 -0.363179  0.363179 -1.004775  1.004775  0.841321 -0.419778   \n",
       "3 -2.661953  0.0 -0.363179  0.363179 -1.004775  1.004775  0.841321  0.369869   \n",
       "4  0.179628  0.0 -0.363179  0.363179  1.031509 -1.031509 -1.233716 -0.194140   \n",
       "\n",
       "         15        16  label  \n",
       "0 -0.564972 -0.556686    0.0  \n",
       "1 -0.528244 -0.493556   -1.0  \n",
       "2 -0.636143 -0.641431    1.0  \n",
       "3  1.460540  1.204818   -1.0  \n",
       "4  0.457735  0.308719   -1.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8 (cse546-data-mining)",
   "language": "python",
   "name": "cse546-data-mining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
